# Capacity Service

Servers used for the provisioning of compute resources for your Kubernetes cluster may come in different flavors: cloud-based virtual machines,  on-premise bare-metal servers, cloud-based bare-metal servers, or on-premise virtual machines. In addition, each cloud service provider (e.g., AWS) offers its vendor server types with different hardware and memory parameters. Managing the selection, instantiation, and scaling of all these diverse server types manually may be a complicated task. 

Supergiant **Capacity Service** is a solution to this problem. The Capacity Service is Supergiant's way of abstracting servers from application management and deployment, allowing the user to focus only on how much CPU, RAM, and disc applications are needed -- not which flavor of a server to use for each application. If you imagine _containerization_ to be similar to hardware-level virtualization (hypervisors partitioning big host machines in the cloud into multiple virtual machines), then the following analogy could be made. Without the Supergiant Capacity Service, running a container orchestration platform like Kubernetes forces DevOps engineers to manage two levels of capacity. That is, they must worry not only about container resource allocation but also about _server allocation_. It would be equally difficult to imagine AWS requiring its users not only to request new servers but also to request additional capacity in the region ahead of time! 

Of course, that would be silly because, after all, cloud servers are generally _on-demand_. That's what the Capacity Service does for Kubernetes containers. Containers can be provisioned on-demand without worrying about server capacity. Supergiant will handle creating Nodes when over capacity, and (gently) deleting Nodes when sufficiently under capacity.

